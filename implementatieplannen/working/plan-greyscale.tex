\documentclass[a4paper]{article}
\usepackage{amsmath}
\usepackage{hyperref}

\usepackage{listings}
\usepackage{color}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=Java,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

\begin{document}
\title{Conversion of RGB images to Intensity images}
\author{Niels de Waal (1698041), Jasper Smienk(1700502)}
\maketitle
\newpage

\tableofcontents
\newpage

\section{Target}
The assignment of TICT-V2VISN1-13 at the HU, which we have chosen to undertake consists of two different components.
The first one consists of writing a image shell which has to ability to extract or modify data from a given image.
The second assignment is to convert an RGB image to an intensity/grey-scale image. 

We will be mostly focusing on the second assignment. This is because we are interested in comparing a few different approaches to this problem.

For the second assignment we will be doing two measuring tests. The first will cover speed across multiple methods of grey-scaling. The second test will revolve around effects on the cpu cache across the different methods of grey-scaling.

Both can be of interest. This could be because testing multiple methods of grey-scaling, including testing the speed at which this can be done could have effects when grey-scaling becomes an integral part of a system. This could happen in a real-time face recognition system, where grey-scaling has to be done every frame.

\section{Methods}
In this section we will discuss several methods of grey-scaling an image.

Let us refer to pixel \(i\) as part of image \(P\), where \(i \in \{0, \dotsc , \left( P_{width} * P_{height} \right) - 1 \} \). Every \(i\) has a set of \( \left(R, G, B \right) \) where \(R\), \(G\) and \(B\) have a range \(\{0, \dotsc ,255 \} \).

\subsection{Methods for grey-scaling}
In this sections a few methods for grey-scaling will be discussed.
There are far too many methods to compare them all, thus in this article we will discuss these three:
\begin{itemize}
\item Averaging
\item Luma
\item Decomposition
\end{itemize}
\subsubsection{Averaging}
This will be considered as the naive approach to grey-scaling. Here we take the RGB values and using the average of them to calculate the grey-scale value. 
With the values: \( \forall i \in P \) the grey-scale is \( \left( i_{R} + i_{G} + i_{B} \right) \div 3 \).

This technique has the advantage that it is very easy to implement and cheap to run. It has the disadvantage that it is not a very good at giving a good representation of a grey-scale image for human eyes.

\subsubsection{Luma}
The luma method fixes the problem that averaging has regarding the correctness for the human eye. Luma gives different priorities to different channels. The values for the different channels are described in \cite{HDTV-REC}.
With the values: \( \forall i \in P \) the grey-scale is \(  i_{R}*0.2126 + i_{G}*0.7152 + i_{B}*0.0722  \).

With this method we could lose speed in comparison to averaging, because of the multiple floating point operations that have to be done each pixel. The upside is that this method delivers better images, because they are suited for the human eye.

\subsubsection{Decomposition}
Decomposition is the simplest method of grey-scaling. This method of grey-scaling has the advantage that it is very cheap to implement and run. The disadvantage is that, depending on the version used, it can result in a vastly lighter or darker image. 
With the values: \( \forall i \in P \) the grey-scale is \(  \max(i_{R}, i_{G}, i_{B}) \) or \(  \min(i_{R}, i_{G}, i_{B}) \).

This method is not adjusted for the human eye. 

\subsection{Cache}
Cache is an imported part of modern cpu architectures. Cpu cache can significantly increase the speed of piece of software. This is because it eliminates the time required of waiting for an value from memory. It does this by loading values from memory ahead of time and writing them to the on-die memory inside the cpu. 

The algorithms and processes by which the cpu decides what values to load is far beyond the scope of this document.

\section{Choice}
In this section we will shortly discuss why we chose the afore mentioned methods for grey-scaling.

\subsection{Grey-scaling}
There are any number of different methods for grey-scaling. Far too many to be explored in this assignment. That is why we will examine the three methods mentioned above.
We chose these methods of grey-scaling for the following reasons:

\begin{itemize}
\item Simple
\item All methods operate on a per pixel basis
\item Because of the per pixel operations, the methods have a high chance of being run in parallel
\item Although the operations are similar they still differ enough that a difference should me measurable
\end{itemize}

\newpage

\section{Implementation}
In this section we present the implementations of the different methods.

\subsection{Grey-scaling}
What follows are the different methods of grey-scaling, implemented in the framework required for this assignment.

The average method:
\lstset{language=C++}
\begin{lstlisting}
IntensityImage * StudentPreProcessing::stepToIntensityImage(const RGBImage &image) const {
        auto* intensityImage = new IntensityImageStudent(image.getWidth(), image.getHeight());

        for (int i = 0; i < (image.getWidth() * image.getHeight()); i++) {

                //Average
                intensityImage->setPixel(i, ((image.getPixel(i).r + image.getPixel(i).g + image.getPixel(i).b) / 3));

        }
        return intensityImage;
}

\end{lstlisting}

The luma method:
\lstset{language=C++}
\begin{lstlisting}
IntensityImage * StudentPreProcessing::stepToIntensityImage(const RGBImage &image) const {
        auto* intensityImage = new IntensityImageStudent(image.getWidth(), image.getHeight());

        for (int i = 0; i < (image.getWidth() * image.getHeight()); i++) {

                //Luma
                intensityImage->setPixel(i, (image.getPixel(i).r * 0.2126 + image.getPixel(i).g * 0.7152 + image.getPixel(i).b * 0.0722));


        }
        return intensityImage;
}

\end{lstlisting}
\newpage

The decomposition method:
\lstset{language=C++}
\begin{lstlisting}
IntensityImage * StudentPreProcessing::stepToIntensityImage(const RGBImage &image) const {
        auto* intensityImage = new IntensityImageStudent(image.getWidth(), image.getHeight());

        for (int i = 0; i < (image.getWidth() * image.getHeight()); i++) {

                //Decomposition; max
                //intensityImage->setPixel(i, std::max({image.getPixel(i).r, image.getPixel(i).g, image.getPixel(i).b}));

                //Decomposition; min
                intensityImage->setPixel(i, std::min({image.getPixel(i).r, image.getPixel(i).g, image.getPixel(i).b}));


        }
        return intensityImage;
}

\end{lstlisting}

\section{Evaluation}
In this section we will discuss the 2 different aspects of the grey-scaling methods that will be measured.

\subsection{Speed}
We will be measuring and comparing the speed of the already discussed methods for grey-scaling. This could be of benefit to anyone wanting to run facial recognition in real-time. These kinds of systems need to process every frame at a relatively high frame-rate. This means that if some time could be saved on the processing of each frame, it would increase the time available to process the rest of a frame.

The speed will be measured by measuring the time required to run through the process of either just grey-scaling, or the full facial recognition process. Our hypothesis is available in our measurement report.

\subsection{Cache behaviour}
This one ties in with the speed measurements. Here we will attempt to find out which of the methods for grey-scaling have the most benefit from the cache. This will be measured by comparing the amount of cache hits and misses. This will give an idea about the efficiency of the methods with regards to cpu caches.

When one method seems to better synergy with the cache, those results could be tied to the results from the first measurement report. We won't be doing that in our measurement report as it will be outside the scope of the measurements presented in those reports.

\begin{thebibliography}{9}

\bibitem{HDTV-REC}
	ITU-R,
	Recommendation  ITU-R  BT.709-6,	
	\url{http://www.itu.int/dms_pubrec/itu-r/rec/bt/R-REC-BT.709-6-201506-I!!PDF-E.pdf}
  
\bibitem{TI-ASC}
	Texas Instruments,
	\url{https://en.wikipedia.org/wiki/TI_Advanced_Scientific_Computer}
 
\bibitem{INTEL-MMX}
Intel,
Pentium processor with MMX,
\url{https://www.intel.com/content/www/us/en/intelligent-systems/previous-generation/embedded-pentium-mmx.html}

\bibitem{OPENCL}
khronos,
OpenCL home page,
\url{https://www.khronos.org/opencl/}

\end{thebibliography}
\end{document}
